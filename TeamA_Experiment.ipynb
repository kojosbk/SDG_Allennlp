{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experement Presentation by Team_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- surmarize a normal passage a combination of extractive and abstractive techniques then after apply it on googles T5 text summarizer\n",
    "\n",
    "- adjust text leanght and observe the outcomes\n",
    "\n",
    "- apply the above  on a data frame\n",
    "\n",
    "- demonstrate a question and answer Model\n",
    "\n",
    "- Apply the question and answer model on a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1  Setting up necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "#models\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from summarizer import Summarizer\n",
    "predictor = Predictor.from_path(\"C:/Users/Silas_Dell/Downloads/Compressed/bidaf-elmo.2021-02-11.tar_2.gz\")\n",
    "\n",
    "# Suppressing unnwarranted warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model and Tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-context",
   "metadata": {},
   "source": [
    "### Input Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "New York (CNN Business)Netflix is synonymous with streaming, but its competitors have a distinct advantage that threatens the streaming leader's position at the top.\n",
    "Disney has Disney+, but it also has theme parks, plush Baby Yoda dolls, blockbuster Marvel movies and ESPN. Comcast (CMCSA), Amazon (AMZN), ViacomCBS (VIACA), CNN's parent company WarnerMedia and Apple (AAPL) all have their own streaming services, too, but they also have other forms of revenue.\n",
    "As for Netflix (NFLX), its revenue driver is based entirely on building its subscriber base. It's worked out well for the company - so far. But it's starting to look like the king of streaming will soon need something other than new subscribers to keep growing.\n",
    "The streaming service reported Tuesday it now has 208 million subscribers globally, after adding 4 million subscribers in the first quarter of 2021. But that number missed expectations and the forecasts for its next quarter were also pretty weak.\n",
    "That was a big whiff for Netflix - a company coming off a massive year of growth thanks in large part to the pandemic driving people indoors - and Wall Street's reaction has not been great.\n",
    "The company's stock dropped as much as 8% on Wednesday, leading some to wonder what the future of the streamer looks like if competition continues to gain strength, people start heading outdoors and if, most importantly, its growth slows.\n",
    "\"If you hit a wall with [subscriptions] then you pretty much don't have a super growth strategy anymore in your most developed markets,\" Michael Nathanson, a media analyst and founding partner at MoffettNathanson, told CNN Business. \"What can they do to take even more revenue out of the market, above and beyond streaming revenues?\"\n",
    "Or put another way, the company's lackluster user growth last quarter is a signal that it wouldn't hurt if Netflix - a company that's lived and died with its subscriber numbers - started thinking about other ways to make money.\n",
    "An ad-supported Netflix? Not so fast\n",
    "There are ways for Netflix to make money other than raising prices or adding subscribers. The most obvious: selling advertising.\n",
    "Netflix could have 30-second commercials on their programming or get sponsors for their biggest series and films. TV has worked that way forever, why not Netflix?\n",
    "That's probably not going to happen, given that CEO Reed Hastings has been vocal about the unlikelihood of an ad-supported Netflix service. His reasoning: It doesn't make business sense.\n",
    "\"It's a judgment call... It's a belief we can build a better business, a more valuable business [without advertising],\" Hastings told Variety in September. \"You know, advertising looks easy until you get in it. Then you realize you have to rip that revenue away from other places because the total ad market isn't growing, and in fact right now it's shrinking. It's hand-to-hand combat to get people to spend less on, you know, ABC and to spend more on Netflix.\"\n",
    "Hastings added that \"there's much more growth in the consumer market than there is in advertising, which is pretty flat.\"\n",
    "He's also expressed doubts about Netflix getting into live sports or news, which could boost the service's allure to subscribers, so that's likely out, too, at least for now.\n",
    "So if Netflix is looking for other forms of near-term revenue to help support its hefty content budget ($17 billion in 2021 alone) then what can it do? There is one place that could be a revenue driver for Netflix, but if you're borrowing your mother's account you won't like it.\n",
    "Netflix could crack down on password sharing - a move that the company has been considering lately.\n",
    "\"Basically you're going to clean up some subscribers that are free riders,\" Nathanson said. \"That's going to help them get to a higher level of penetration, definitely, but not in long-term.\"\n",
    "Lackluster growth is still growth\n",
    "Missing projections is never good, but it's hardly the end of the world for Netflix. The company remains the market leader and most competitors are still far from taking the company on. And while Netflix's first-quarter subscriber growth wasn't great, and its forecasts for the next quarter alarmed investors, it was just one quarter.\n",
    "Netflix has had subscriber misses before and it's still the most dominant name in all of streaming, and even lackluster growth is still growth. It's not as if people are canceling Netflix in droves.\n",
    "Asked about Netflix's \"second act\" during the company's post-earnings call on Tuesday, Hastings again placed the company's focus on pleasing subscribers.\n",
    "\"We do want to expand. We used to do that thing shipping DVDs, and luckily we didn't get stuck with that. We didn't define that as the main thing. We define entertainment as the main thing,\" Hastings said.\n",
    "He added that he doesn't think Netflix will have a second act in the way Amazon has had with Amazon shopping and Amazon Web Services. Rather, Netflix will continue to improve and grow on what it already does best.\n",
    "\"I'll bet we end with one hopefully gigantic, hopefully defensible profit pool, and continue to improve the service for our members,\" he said. \"I wouldn't look for any large secondary pool of profits. There will be a bunch of supporting pools, like consumer products, that can be both profitable and can support the title brands.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-contact",
   "metadata": {},
   "source": [
    "## Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input = tokenizer.encode(\"summarize: \"+text, return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(tokens_input, min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2)\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of tokens generated from the text using T5 Tokenizer\n",
    "len(tokenizer(text)['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-amount",
   "metadata": {},
   "source": [
    "Using BERT summarizer to extract only top 50% of sentences that are considered important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = Summarizer()\n",
    "ext_summary = bert_model(text, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ext_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-mitchell",
   "metadata": {},
   "source": [
    "## Tokenize BERT Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_2 = tokenizer.encode(\"summarize: \"+ext_summary, return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer(ext_summary)['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-webmaster",
   "metadata": {},
   "source": [
    "## Extractive-Abstractive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids_2 = model.generate(tokens_input_2, min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2)\n",
    "\n",
    "summary_2 = tokenizer.decode(summary_ids_2[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "AMONG the numerous mechanisms that make human life possible is the body’s ability to heal wounds and regenerate damaged tissue. The process begins as soon as an injury occurs.\n",
    "Consider: The healing process is made possible by a cascade of complex cellular functions:\n",
    "Platelets adhere to tissues around a wound, forming a blood clot and sealing damaged blood vessels.\n",
    "Inflammation protects against infection and removes any “debris” caused by the injury.\n",
    "Within days, the body begins to replace injured tissue, make the wound contract, and repair damaged blood vessels.\n",
    "Finally, scar tissue remodels and strengthens the damaged area.\n",
    "Inspired by blood clotting, researchers are developing plastics that can “heal” \n",
    "damage to themselves. Such regenerating materials are equipped with tiny parallel \n",
    "tubes containing two chemicals that “bleed” when any damage occurs. As the two \n",
    "chemicals mix, they form a gel that spreads across the damaged areas, closing \n",
    "cracks and holes. As the gel solidifies, it forms a tough substance that restores \n",
    "the material’s original strength. One researcher admits that this synthetic healing process currently under development is “reminiscent” of what already exists in nature.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input = tokenizer.encode(\"summarize: \"+text1, return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(tokens_input, min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2)\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of tokens generated from the text using T5 Tokenizer\n",
    "len(tokenizer(text)['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('guardian_publications.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 5 rows to work on\n",
    "train = train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(train[\"text\"])):\n",
    "    result.append(tokenizer.encode(\"summarize: \"+train[\"text\"][i], return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tokens_input\"]=result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = []\n",
    "for i in range(len(train[\"tokens_input\"])):\n",
    "    result1.append(model.generate(train[\"tokens_input\"][i], min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"summary_ids\"]=result1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = []\n",
    "for i in range(len(train[\"summary_ids\"])):\n",
    "    result2.append(tokenizer.decode((train[\"summary_ids\"][i])[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = []\n",
    "for i in range(len(train[\"text\"])):\n",
    "    result3.append(len(tokenizer(train[\"text\"][i])['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"summary\"]=result2\n",
    "train[\"No.tokens\"]=result3\n",
    "train[[\"text\",\"No.tokens\",\"summary\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Q & A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = '''Indicators for targets 9.b and 9.c have data available. Globally, \n",
    "energy efficiency and the use of cleaner fuels and technologies reduced carbon dioxide emissions \n",
    "per unit of value added by 13 per cent between 2000 and 2013. Although expenditure on research and \n",
    "development continues to grow globally, the poorest countries, especially those in Africa, spend a very small \n",
    "proportion of their GDP on such expenditure. In 2013, global investment in research and development stood at $1.7 trillion \n",
    "(purchasing power parity), up from $732 billion in 2000.\n",
    "this is labeled as '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(passage=passage, question=\"how much was the investment?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"best_span_str\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qestions(data:train,column,question) -> train:\n",
    "    result = []\n",
    "    for i in range(len(train[column])):\n",
    "        result.append(predictor.predict(passage=train[column][i], question=question)[\"best_span_str\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[[\"text\",\"No.tokens\",\"summary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Is Shell implicated?\"] = qestions(train,column= \"text\", question = \"Is Shell implicated?\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "predictor = Predictor.from_path(\"C:/Users/Silas_Dell/Downloads/Compressed/ner-elmo.2021-02-12.tar.gz\")\n",
    "predictor.predict(\n",
    "    sentence=\"Did Uriah honestly think he could beat The Legend of Zelda in under three hours?.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp_models.pretrained import load_predictor\n",
    "predictor = load_predictor(\"tagging-elmo-crf-tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs U-PER\n",
      "and O\n",
      "Wozniak U-PER\n",
      "cofounded O\n",
      "Apple U-ORG\n",
      "in O\n",
      "1976 O\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Jobs and Wozniak cofounded Apple in 1976.\"\n",
    "preds = predictor.predict(sentence)\n",
    "for word, tag in zip(preds[\"words\"], preds[\"tags\"]):\n",
    "    print(word, tag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "320c1f05b41b6296d6cdeadbc8f37198b22e160db062b16d8b8cc9d95c25d782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
