{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experement Presentation by Team_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- surmarize a normal passage a combination of extractive and abstractive techniques then after apply it on googles T5 text summarizer\n",
    "\n",
    "- adjust text leanght and observe the outcomes\n",
    "\n",
    "- apply the above  on a data frame\n",
    "\n",
    "- demonstrate a question and answer Model\n",
    "\n",
    "- Apply the question and answer model on a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1  Setting up necessary libraries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 141,
=======
   "execution_count": 1,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\SILAS_~1\\AppData\\Local\\Temp\\tmppjg4of76\\config.json as plain json\n"
=======
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\SILAS_~1\\AppData\\Local\\Temp\\tmp8w6q5o7p\\config.json as plain json\n"
>>>>>>> Stashed changes
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "#models\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from summarizer import Summarizer\n",
    "#predictor = Predictor.from_path(\"C:/Users/Silas_Dell/Downloads/Compressed/bidaf-elmo.2021-02-11.tar_2.gz\")\n",
    "\n",
    "# Suppressing unnwarranted warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 142,
=======
   "execution_count": 3,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model and Tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-context",
   "metadata": {},
   "source": [
    "### Input Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 143,
=======
   "execution_count": 10,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Most important, the words of 1 Kings 14:13 teach us something beautiful about Jehovah and what he looks for in us. Recall that something good was “found in” Abijah. Jehovah evidently searched through Abijah’s heart until He found a trace of goodness. Compared to his family, Abijah was, as one scholar put it, the lone pearl “in a heap of pebbles.” Jehovah cherished this goodness and rewarded it, granting a measure of mercy to this one member of a wicked family.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-contact",
   "metadata": {},
   "source": [
    "## Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 144,
=======
   "execution_count": 11,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "entitled-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input = tokenizer.encode(\"summarize: \"+text, return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 145,
=======
   "execution_count": 12,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "resident-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(tokens_input, min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2)\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 146,
=======
   "execution_count": 13,
>>>>>>> Stashed changes
   "id": "comic-tribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compared to his family, Abijah was, as one scholar put it, the lone pearl \"in a heap of pebbles\" Jehovah evidently searched through Abijah’s heart until He found a trace of goodness. he rewarded this goodness, granting a measure of mercy to this one member of a wicked family. he was a lone pearl \"in a heap of pebbles\" and a member of a wicked family.\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "comic-tribe",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 147,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "lasting-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1237 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1237"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "id": "lasting-microphone",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "# number of tokens generated from the text using T5 Tokenizer\n",
    "len(tokenizer(text)['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-amount",
   "metadata": {},
   "source": [
    "Using BERT summarizer to extract only top 50% of sentences that are considered important."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 148,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "hollow-optimization",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "id": "hollow-optimization",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "bert_model = Summarizer()\n",
    "ext_summary = bert_model(text, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 149,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ext_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-mitchell",
   "metadata": {},
   "source": [
    "## Tokenize BERT Summary"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 150,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "modular-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_2 = tokenizer.encode(\"summarize: \"+ext_summary, return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 151,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "latter-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "id": "latter-formation",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "len(tokenizer(ext_summary)['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-webmaster",
   "metadata": {},
   "source": [
    "## Extractive-Abstractive Summary"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 152,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "ranking-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids_2 = model.generate(tokens_input_2, min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2)\n",
    "\n",
    "summary_2 = tokenizer.decode(summary_ids_2[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 153,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "monetary-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_2)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 154,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"\n",
    "AMONG the numerous mechanisms that make human life possible is the body’s ability to heal wounds and regenerate damaged tissue. The process begins as soon as an injury occurs.\n",
    "Consider: The healing process is made possible by a cascade of complex cellular functions:\n",
    "Platelets adhere to tissues around a wound, forming a blood clot and sealing damaged blood vessels.\n",
    "Inflammation protects against infection and removes any “debris” caused by the injury.\n",
    "Within days, the body begins to replace injured tissue, make the wound contract, and repair damaged blood vessels.\n",
    "Finally, scar tissue remodels and strengthens the damaged area.\n",
    "Inspired by blood clotting, researchers are developing plastics that can “heal” \n",
    "damage to themselves. Such regenerating materials are equipped with tiny parallel \n",
    "tubes containing two chemicals that “bleed” when any damage occurs. As the two \n",
    "chemicals mix, they form a gel that spreads across the damaged areas, closing \n",
    "cracks and holes. As the gel solidifies, it forms a tough substance that restores \n",
    "the material’s original strength. One researcher admits that this synthetic healing process currently under development is “reminiscent” of what already exists in nature.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 155,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "entitled-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input = tokenizer.encode(\"summarize: \"+text1, return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 156,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "resident-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(tokens_input, min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2)\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 157,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "comic-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 158,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "lasting-microphone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "id": "lasting-microphone",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "# number of tokens generated from the text using T5 Tokenizer\n",
    "len(tokenizer(text)['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data frames"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 159,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('guardian_publications.csv')\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 161,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 5 rows to work on\n",
    "train = train.head(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 162,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(train[\"text\"])):\n",
    "    result.append(tokenizer.encode(\"summarize: \"+train[\"text\"][i], return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 163,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tokens_input\"]=result\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 164,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = []\n",
    "for i in range(len(train[\"tokens_input\"])):\n",
    "    result1.append(model.generate(train[\"tokens_input\"][i], min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 165,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"summary_ids\"]=result1\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 166,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = []\n",
    "for i in range(len(train[\"summary_ids\"])):\n",
    "    result2.append(tokenizer.decode((train[\"summary_ids\"][i])[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 167,
=======
   "execution_count": null,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = []\n",
    "for i in range(len(train[\"text\"])):\n",
    "    result3.append(len(tokenizer(train[\"text\"][i])['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 168,
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>No.tokens</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shell’s long-serving chief executive, Ben van ...</td>\n",
       "      <td>698</td>\n",
       "      <td>van Beurden, who took over in 2014, would leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A South African court has upheld a ban imposed...</td>\n",
       "      <td>395</td>\n",
       "      <td>the 2014 decision granting the right for the \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gas shortages across Europe are likely to last...</td>\n",
       "      <td>1022</td>\n",
       "      <td>cuts to the supply of Russian gas since the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell has agreed to pay half a million pounds ...</td>\n",
       "      <td>680</td>\n",
       "      <td>energy giant's consumer arm, shell energy reta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The chair of the Church of England Pensions Bo...</td>\n",
       "      <td>1405</td>\n",
       "      <td>the church of england has rejected pressure to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  No.tokens  \\\n",
       "0  Shell’s long-serving chief executive, Ben van ...        698   \n",
       "1  A South African court has upheld a ban imposed...        395   \n",
       "2  Gas shortages across Europe are likely to last...       1022   \n",
       "3  Shell has agreed to pay half a million pounds ...        680   \n",
       "4  The chair of the Church of England Pensions Bo...       1405   \n",
       "\n",
       "                                             summary  \n",
       "0  van Beurden, who took over in 2014, would leav...  \n",
       "1  the 2014 decision granting the right for the \"...  \n",
       "2  cuts to the supply of Russian gas since the in...  \n",
       "3  energy giant's consumer arm, shell energy reta...  \n",
       "4  the church of england has rejected pressure to...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "train[\"summary\"]=result2\n",
    "train[\"No.tokens\"]=result3\n",
    "train[[\"text\",\"No.tokens\",\"summary\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Q & A"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 169,
=======
   "execution_count": 7,
>>>>>>> Stashed changes
=======
   "execution_count": null,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = '''Most important, the words of 1 Kings 14:13 teach us something beautiful about Jehovah and what he looks for in us. Recall that something good was “found in” Abijah. Jehovah evidently searched through Abijah’s heart until He found a trace of goodness. Compared to his family, Abijah was, as one scholar put it, the lone pearl “in a heap of pebbles.” Jehovah cherished this goodness and rewarded it, granting a measure of mercy to this one member of a wicked family.'''"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 170,
=======
   "execution_count": 8,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(passage=passage, question=\"What does this verse teach us about Jehovah?\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 171,
=======
   "execution_count": 9,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'something beautiful'"
      ]
     },
<<<<<<< Updated upstream
     "execution_count": 171,
=======
     "execution_count": 9,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "result[\"best_span_str\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frames"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qestions(df,column,question):\n",
    "    result = []\n",
    "    for i in range(len(df[column])):\n",
    "        result.append(predictor.predict(passage=train[column][i], question=question)[\"best_span_str\"])\n",
    "    return result"
=======
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = '''Indicators for targets 9.b and 9.c have data available. Globally, \n",
    "energy efficiency and the use of cleaner fuels and technologies reduced carbon dioxide emissions \n",
    "per unit of value added by 13 per cent between 2000 and 2013. Although expenditure on research and \n",
    "development continues to grow globally, the poorest countries, especially those in Africa, spend a very small \n",
    "proportion of their GDP on such expenditure. In 2013, global investment in research and development stood at $1.7 trillion \n",
    "(purchasing power parity), up from $732 billion in 2000.\n",
    "this is labeled as '''"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> Stashed changes
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qesAns(df,questions = \"Is Shell implicated?\"):\n",
    "\n",
    "        def qestions(df,column,question):\n",
    "            result = []\n",
    "            for i in range(len(train[column])):\n",
    "                result.append(predictor.predict(passage=train[column][i], question=question)[\"best_span_str\"])\n",
    "            return result\n",
    "\n",
    "        train[questions] = qestions(df,column= \"text\", question = questions)\n",
    "        return train[questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Shell declined to comment on Van Beurden’s pen...\n",
       "1    Shell did not say if it would appeal against t...\n",
       "2    Shell made record profits of nearly £10bn betw...\n",
       "3    had Shell not self-reported the issue and take...\n",
       "4    it is no longer ethical to profit from fossil ...\n",
       "Name: Is Shell implicated?, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "qesAns(train,questions= \"Is Shell implicated?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Shell declined to comment on Van Beurden’s pen...\n",
       "1    Shell did not say if it would appeal against t...\n",
       "2    Shell made record profits of nearly £10bn betw...\n",
       "3    The contributions Shell has made to the redres...\n",
       "4    short-term expansion plans amount to about 4bn...\n",
       "Name: Is Shell involved?, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qesAns(train,questions= \"Is Shell involved?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      Google reCaptcha\n",
       "1                                            3D seismic\n",
       "2                                      Google reCaptcha\n",
       "3                                      Google reCaptcha\n",
       "4                                      Google reCaptcha\n",
       "5     strong refining profit margins, and promised t...\n",
       "6                                     refining capacity\n",
       "7                                    a lower carbon one\n",
       "8                                         social tariff\n",
       "9     Consumer spending is continuing to grow. Earli...\n",
       "10                               secure energy supplies\n",
       "11                          very strong cash generation\n",
       "12                                     Google reCaptcha\n",
       "13                                     Google reCaptcha\n",
       "14                                           3D seismic\n",
       "15                                     Google reCaptcha\n",
       "16                                     Google reCaptcha\n",
       "17                                     Google reCaptcha\n",
       "18    strong refining profit margins, and promised t...\n",
       "19                                               google\n",
       "20                                               google\n",
       "21                                    refining capacity\n",
       "22                      Fed inflation-fighting measures\n",
       "23                                   a lower carbon one\n",
       "24                                        social tariff\n",
       "25    Consumer spending is continuing to grow. Earli...\n",
       "26                               secure energy supplies\n",
       "Name: what technology did shell use?, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "outputs": [],
   "source": [
    "summarize_text(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qesAns(df,questions = \"Is Shell implicated?\"):\n",
    "\n",
    "        def qestions(df,column,question):\n",
    "            result = []\n",
    "            for i in range(len(train[column])):\n",
    "                result.append(predictor.predict(passage=train[column][i], question=question)[\"best_span_str\"])\n",
    "            return result\n",
    "\n",
    "        train[questions] = qestions(df,column= \"text\", question = questions)\n",
    "        return train[questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qesAns(train,questions= \"Is Shell implicated?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answering different questions from predefined options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "qesAns(train,questions= \"what technology did shell use?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
   "id": "acf76510",
=======
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from allennlp.predictors import Predictor\n",
    "from allennlp_models.pretrained import load_predictor"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 29,
>>>>>>> Stashed changes
   "id": "f9d6e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_models = [\n",
    "    { 'name' : 'ner-model',\n",
    "      'url': 'https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz'\n",
    "    },\n",
    "    # { 'name' : 'ner-elmo',\n",
    "    #   'url' : 'https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz',\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 30,
>>>>>>> Stashed changes
   "id": "9766901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Loading model : ner-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\SILAS_~1\\AppData\\Local\\Temp\\tmpro27hmfp\\config.json as plain json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'ner-model' in 31,042.0 milli seconds\n",
      "\n"
=======
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\lista\\AppData\\Local\\Temp\\tmppzkyp87y\\config.json as plain json\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "## load models\n",
    "print (\"Loading models...\")\n",
    "for nlp_model in nlp_models:\n",
    "    print (\"Loading model :\", nlp_model['name'])\n",
    "    t1 = time.perf_counter()\n",
    "    nlp_model['model'] = Predictor.from_path(nlp_model['url'])\n",
    "    t2 = time.perf_counter()\n",
    "    print (\"Loaded model '{}' in {:,.1f} milli seconds\".format (nlp_model['name'], (t2-t1)*1e3))\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locationOrganization(train):\n",
    "    \n",
    "        '''\n",
    "        This function takes in a dataframe and extract information out of the text column\n",
    "        Args:\n",
    "            source training data\n",
    "        \n",
    "        Returns:\n",
    "            a data frame answering the asked question \n",
    "            based on each article in each row\n",
    "        '''\n",
=======
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locationOrganization1(train):\n",
    "        train = train.head(3)\n",
>>>>>>> Stashed changes
    "        def entity_recognition (sentence):\n",
    "            location = []\n",
    "            for nlp_model in nlp_models:\n",
    "                results =  nlp_model['model'].predict(sentence=sentence)\n",
    "                for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "                    if tag != 'U-LOC':\n",
    "                        continue\n",
    "                    else:\n",
    "                        # print([word])#(f\"{word}\")\n",
    "                        location.append(word)\n",
    "                # print()\n",
    "                return location\n",
    "\n",
    "        def entity_recognition_pe(sentence):\n",
    "            organisation = []\n",
    "            for nlp_model in nlp_models:\n",
    "                results =  nlp_model['model'].predict(sentence=sentence)\n",
    "                for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "                    if tag != 'U-ORG':\n",
    "                        continue\n",
    "                    else:\n",
    "                        # print([word])#(f\"{word}\")\n",
    "                        organisation.append(word)\n",
    "                # print()\n",
    "                return organisation\n",
    "        result = []\n",
    "        for i in range(len(train[\"text\"])):\n",
    "            result.append(list(set(entity_recognition(train[\"text\"][i]))))\n",
    "        re1 = []\n",
    "        for i in range(len(train[\"text\"])):\n",
    "            re1.append(list(set(entity_recognition_pe(train[\"text\"][i]))))\n",
    "        train[\"location\"]=result\n",
    "        train[\"organisation\"]=re1\n",
    "        return train[[\"text\",\"location\",\"organisation\"]]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\lista\\AppData\\Local\\Temp\\tmp4ga070jo\\config.json as plain json\n"
     ]
    }
   ],
   "source": [
    "nlp_model = Predictor.from_path('https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def locationOrganization(data):\n",
    "    data= data.head(10)\n",
    "    def entity_recognition (sentence):\n",
    "        location = []\n",
    "        organisation = []\n",
    "        results =  nlp_model.predict(sentence=sentence)\n",
    "        for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "            if tag != 'U-LOC' or tag != 'U-ORG':\n",
    "                continue\n",
    "            elif tag == 'U-ORG':\n",
    "                organisation.append(word)\n",
    "            else:\n",
    "                # print([word])#(f\"{word}\")\n",
    "                location.append(word)\n",
    "            # print()\n",
    "            data2=pd.DataFrame({\"locations\":location, \"organisations\":organisation})\n",
    "            return data2       \n",
    "                \n",
    "    result = pd.DataFrame()\n",
    "    for i in range(len(train[\"text\"])):\n",
    "        result.append(entity_recognition(train[\"text\"][i]))\n",
    "    data=pd.concat([data, result], axis=1)\n",
    "    return data[[\"text\",\"location\",\"organisation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = locationOrganization(train)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>organisation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shell’s long-serving chief executive, Ben van ...</td>\n",
<<<<<<< Updated upstream
       "      <td>[Netherlands, Norway, Ukraine, Russia, Europe,...</td>\n",
       "      <td>[Reuters, Shell]</td>\n",
=======
       "      <td>Netherlands, UK, Norway, Russia, London, Europ...</td>\n",
       "      <td>Shell, Reuters</td>\n",
>>>>>>> Stashed changes
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A South African court has upheld a ban imposed...</td>\n",
<<<<<<< Updated upstream
       "      <td>[Algoa, Transkei, Makhanda]</td>\n",
       "      <td>[Shell]</td>\n",
=======
       "      <td>Makhanda, Algoa, Transkei</td>\n",
       "      <td>Shell</td>\n",
>>>>>>> Stashed changes
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gas shortages across Europe are likely to last...</td>\n",
<<<<<<< Updated upstream
       "      <td>[Britain, Belgium, Norway, Slovenia, Germany, ...</td>\n",
       "      <td>[TotalEnergies, Newsletters, Shell, Gazprom, EU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell has agreed to pay half a million pounds ...</td>\n",
       "      <td>[Britain, UK]</td>\n",
       "      <td>[Shell, Ofgem, ’re]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The chair of the Church of England Pensions Bo...</td>\n",
       "      <td>[Canada, Paris, Britain, Bangladesh, Ascot, Ba...</td>\n",
       "      <td>[Newsletters, Shell, BP, Guardian, Mather, Bap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shell is handing nearly all its 82,000 staff a...</td>\n",
       "      <td>[Ukraine, Russia, UK]</td>\n",
       "      <td>[BP, Shell, Cornwall, Ofgem, @BusinessDesk, Opec]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The US’s biggest oil companies pumped out reco...</td>\n",
       "      <td>[Guyana, Britain, Irving, Texas, US, Ukraine, ...</td>\n",
       "      <td>[ExxonMobil, Shell, O’Grady, Chevron, Exxon, ’re]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BP’s Bernard Looney put it more succinctly las...</td>\n",
       "      <td>[US, Ukraine, Russia, UK]</td>\n",
       "      <td>[BP, Shell, Brent, Centrica, WhatsApp, Rough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soaring profits at two of the UK’s biggest ene...</td>\n",
       "      <td>[Europe, Ukraine, Russia, UK]</td>\n",
       "      <td>[Treasury, Shell, PoliticsHome, Centrica, Labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15.04 Biden: No surprise economy is slowing as...</td>\n",
       "      <td>[US, Korea]</td>\n",
       "      <td>[House, Fed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shell made record profits of nearly £10bn betw...</td>\n",
       "      <td>[Kremlin, Ukraine, Russia, UK]</td>\n",
       "      <td>[Shell, Gazprom, Centrica, Sakhalin-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Filters BETA Key events ( 3 )  1m ago 08.31 Sh...</td>\n",
       "      <td>[Beirut, Spain]</td>\n",
       "      <td>[IBEX, Shell, Sawan, Reuters, ’re]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shell has appointed Wael Sawan, a 25-year comp...</td>\n",
       "      <td>[Beirut, Netherlands, London, Europe]</td>\n",
       "      <td>[’s, Newsletters, Shell, Sawan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Shell’s long-serving chief executive, Ben van ...</td>\n",
       "      <td>[Netherlands, Norway, Ukraine, Russia, Europe,...</td>\n",
       "      <td>[Reuters, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A South African court has upheld a ban imposed...</td>\n",
       "      <td>[Algoa, Transkei, Makhanda]</td>\n",
       "      <td>[Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gas shortages across Europe are likely to last...</td>\n",
       "      <td>[Britain, Belgium, Norway, Slovenia, Germany, ...</td>\n",
       "      <td>[TotalEnergies, Newsletters, Shell, Gazprom, EU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shell has agreed to pay half a million pounds ...</td>\n",
       "      <td>[Britain, UK]</td>\n",
       "      <td>[Shell, Ofgem, ’re]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The chair of the Church of England Pensions Bo...</td>\n",
       "      <td>[Canada, Paris, Britain, Bangladesh, Ascot, Ba...</td>\n",
       "      <td>[Newsletters, Shell, BP, Guardian, Mather, Bap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Shell is handing nearly all its 82,000 staff a...</td>\n",
       "      <td>[Ukraine, Russia, UK]</td>\n",
       "      <td>[BP, Shell, Cornwall, Ofgem, @BusinessDesk, Opec]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What term do you want to search? Search with g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What term do you want to search? Search with g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The US’s biggest oil companies pumped out reco...</td>\n",
       "      <td>[Guyana, Britain, Irving, Texas, US, Ukraine, ...</td>\n",
       "      <td>[ExxonMobil, Shell, O’Grady, Chevron, Exxon, ’re]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Biden says US economic slowdown due to Fed inf...</td>\n",
       "      <td>[US]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BP’s Bernard Looney put it more succinctly las...</td>\n",
       "      <td>[US, Ukraine, Russia, UK]</td>\n",
       "      <td>[BP, Shell, Brent, Centrica, WhatsApp, Rough, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Soaring profits at two of the UK’s biggest ene...</td>\n",
       "      <td>[Europe, Ukraine, Russia, UK]</td>\n",
       "      <td>[Treasury, Shell, PoliticsHome, Centrica, Labo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15.04 Biden: No surprise economy is slowing as...</td>\n",
       "      <td>[US, Korea]</td>\n",
       "      <td>[House, Fed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shell made record profits of nearly £10bn betw...</td>\n",
       "      <td>[Kremlin, Ukraine, Russia, UK]</td>\n",
       "      <td>[Shell, Gazprom, Centrica, Sakhalin-2]</td>\n",
=======
       "      <td>Norway, Russia, Europe, Germany, Slovenia, Ukr...</td>\n",
       "      <td>Gazprom, Newsletters, EU, Shell, TotalEnergies</td>\n",
>>>>>>> Stashed changes
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   Shell’s long-serving chief executive, Ben van ...   \n",
       "1   A South African court has upheld a ban imposed...   \n",
       "2   Gas shortages across Europe are likely to last...   \n",
       "3   Shell has agreed to pay half a million pounds ...   \n",
       "4   The chair of the Church of England Pensions Bo...   \n",
       "5   Shell is handing nearly all its 82,000 staff a...   \n",
       "6   The US’s biggest oil companies pumped out reco...   \n",
       "7   BP’s Bernard Looney put it more succinctly las...   \n",
       "8   Soaring profits at two of the UK’s biggest ene...   \n",
       "9   15.04 Biden: No surprise economy is slowing as...   \n",
       "10  Shell made record profits of nearly £10bn betw...   \n",
       "11  Filters BETA Key events ( 3 )  1m ago 08.31 Sh...   \n",
       "12  Shell has appointed Wael Sawan, a 25-year comp...   \n",
       "13  Shell’s long-serving chief executive, Ben van ...   \n",
       "14  A South African court has upheld a ban imposed...   \n",
       "15  Gas shortages across Europe are likely to last...   \n",
       "16  Shell has agreed to pay half a million pounds ...   \n",
       "17  The chair of the Church of England Pensions Bo...   \n",
       "18  Shell is handing nearly all its 82,000 staff a...   \n",
       "19  What term do you want to search? Search with g...   \n",
       "20  What term do you want to search? Search with g...   \n",
       "21  The US’s biggest oil companies pumped out reco...   \n",
       "22  Biden says US economic slowdown due to Fed inf...   \n",
       "23  BP’s Bernard Looney put it more succinctly las...   \n",
       "24  Soaring profits at two of the UK’s biggest ene...   \n",
       "25  15.04 Biden: No surprise economy is slowing as...   \n",
       "26  Shell made record profits of nearly £10bn betw...   \n",
       "\n",
<<<<<<< Updated upstream
       "                                             location  \\\n",
       "0   [Netherlands, Norway, Ukraine, Russia, Europe,...   \n",
       "1                         [Algoa, Transkei, Makhanda]   \n",
       "2   [Britain, Belgium, Norway, Slovenia, Germany, ...   \n",
       "3                                       [Britain, UK]   \n",
       "4   [Canada, Paris, Britain, Bangladesh, Ascot, Ba...   \n",
       "5                               [Ukraine, Russia, UK]   \n",
       "6   [Guyana, Britain, Irving, Texas, US, Ukraine, ...   \n",
       "7                           [US, Ukraine, Russia, UK]   \n",
       "8                       [Europe, Ukraine, Russia, UK]   \n",
       "9                                         [US, Korea]   \n",
       "10                     [Kremlin, Ukraine, Russia, UK]   \n",
       "11                                    [Beirut, Spain]   \n",
       "12              [Beirut, Netherlands, London, Europe]   \n",
       "13  [Netherlands, Norway, Ukraine, Russia, Europe,...   \n",
       "14                        [Algoa, Transkei, Makhanda]   \n",
       "15  [Britain, Belgium, Norway, Slovenia, Germany, ...   \n",
       "16                                      [Britain, UK]   \n",
       "17  [Canada, Paris, Britain, Bangladesh, Ascot, Ba...   \n",
       "18                              [Ukraine, Russia, UK]   \n",
       "19                                                 []   \n",
       "20                                                 []   \n",
       "21  [Guyana, Britain, Irving, Texas, US, Ukraine, ...   \n",
       "22                                               [US]   \n",
       "23                          [US, Ukraine, Russia, UK]   \n",
       "24                      [Europe, Ukraine, Russia, UK]   \n",
       "25                                        [US, Korea]   \n",
       "26                     [Kremlin, Ukraine, Russia, UK]   \n",
       "\n",
       "                                         organisation  \n",
       "0                                    [Reuters, Shell]  \n",
       "1                                             [Shell]  \n",
       "2    [TotalEnergies, Newsletters, Shell, Gazprom, EU]  \n",
       "3                                 [Shell, Ofgem, ’re]  \n",
       "4   [Newsletters, Shell, BP, Guardian, Mather, Bap...  \n",
       "5   [BP, Shell, Cornwall, Ofgem, @BusinessDesk, Opec]  \n",
       "6   [ExxonMobil, Shell, O’Grady, Chevron, Exxon, ’re]  \n",
       "7   [BP, Shell, Brent, Centrica, WhatsApp, Rough, ...  \n",
       "8   [Treasury, Shell, PoliticsHome, Centrica, Labo...  \n",
       "9                                        [House, Fed]  \n",
       "10             [Shell, Gazprom, Centrica, Sakhalin-2]  \n",
       "11                 [IBEX, Shell, Sawan, Reuters, ’re]  \n",
       "12                    [’s, Newsletters, Shell, Sawan]  \n",
       "13                                   [Reuters, Shell]  \n",
       "14                                            [Shell]  \n",
       "15   [TotalEnergies, Newsletters, Shell, Gazprom, EU]  \n",
       "16                                [Shell, Ofgem, ’re]  \n",
       "17  [Newsletters, Shell, BP, Guardian, Mather, Bap...  \n",
       "18  [BP, Shell, Cornwall, Ofgem, @BusinessDesk, Opec]  \n",
       "19                                                 []  \n",
       "20                                                 []  \n",
       "21  [ExxonMobil, Shell, O’Grady, Chevron, Exxon, ’re]  \n",
       "22                                                 []  \n",
       "23  [BP, Shell, Brent, Centrica, WhatsApp, Rough, ...  \n",
       "24  [Treasury, Shell, PoliticsHome, Centrica, Labo...  \n",
       "25                                       [House, Fed]  \n",
       "26             [Shell, Gazprom, Centrica, Sakhalin-2]  "
      ]
     },
     "execution_count": 179,
=======
       "                                            location  \\\n",
       "0  Netherlands, UK, Norway, Russia, London, Europ...   \n",
       "1                          Makhanda, Algoa, Transkei   \n",
       "2  Norway, Russia, Europe, Germany, Slovenia, Ukr...   \n",
       "\n",
       "                                     organisation  \n",
       "0                                  Shell, Reuters  \n",
       "1                                           Shell  \n",
       "2  Gazprom, Newsletters, EU, Shell, TotalEnergies  "
      ]
     },
     "execution_count": 44,
>>>>>>> Stashed changes
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "train = locationOrganization(train)\n",
    "train"
=======
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = []\n",
    "a_list.extend(train['location'].tolist())\n",
    "# a_list.extend(train['country'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ()\n",
    "for values in train.location.iteritems():\n",
    "        x += values\n",
    "\n",
    "passage=str(x)\n",
    "passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage1 = passage.replace(\"'\", \"\")\n",
    "# passage1 = passage.replace(\"(\", \"\")\n",
    "# passage1 = passage.replace(\")\", \"\")\n",
    "passage1 = ''.join([i for i in passage1 if not i.isdigit()])\n",
    "passage1 = passage1\n",
    "passage1"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
   "id": "943b396f",
=======
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_recognition (sentence):\n",
    "    miscellaneous = []\n",
    "    person = []\n",
    "    organisation = []\n",
    "    location = []\n",
    "    for nlp_model in nlp_models:\n",
    "        results =  nlp_model['model'].predict(sentence=sentence)\n",
    "        for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "            if tag != 'U-LOC':\n",
    "                continue\n",
    "            else:\n",
<<<<<<< Updated upstream
    "                # print([word])#(f\"{word}\")\n",
    "                location.append(word)\n",
    "        # print()\n",
    "        return location\n"
=======
    "                loc.append(word)\n",
    "        print(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_recognition (passage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installation\n",
    "# pip install pycountry-convert\n",
    "#function to convert to alpah2 country codes and continents\n",
    "from pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2\n",
    "def get_continent(col):\n",
    "    try:\n",
    "        cn_a2_code =  country_name_to_country_alpha2(col)\n",
    "    except:\n",
    "        cn_a2_code = 'Unknown' \n",
    "    try:\n",
    "        cn_continent = country_alpha2_to_continent_code(cn_a2_code)\n",
    "    except:\n",
    "        cn_continent = 'Unknown' \n",
    "    return (cn_a2_code, cn_continent)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_recognition_per (sentence):\n",
    "    miscellaneous = []\n",
    "    person = []\n",
    "    organisation = []\n",
    "    location = []\n",
    "    for nlp_model in nlp_models:\n",
    "        results =  nlp_model['model'].predict(sentence=sentence)\n",
    "        for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "            if tag != 'U-ORG':\n",
    "                continue\n",
    "            else:\n",
    "                # print([word])#(f\"{word}\")\n",
    "                organisation.append(word)\n",
    "        # print()\n",
    "        return organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
=======
   "metadata": {},
   "outputs": [],
   "source": [
    "#installation\n",
    "# pip install folium\n",
    "# Create a world map to show distributions of users \n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "#empty map\n",
    "world_map= folium.Map(tiles=\"cartodbpositron\")\n",
    "marker_cluster = MarkerCluster().add_to(world_map)\n",
    "#for each coordinate, create circlemarker of user percent\n",
    "for i in range(len(df)):\n",
    "        lat = df.iloc[i]['Latitude']\n",
    "        long = df.iloc[i]['Longitude']\n",
    "        radius=5\n",
    "        popup_text = \"\"\"Country : {}<br>\n",
    "                    %of Users : {}<br>\"\"\"\n",
    "        popup_text = popup_text.format(df.iloc[i]['Country'],\n",
    "                                   df.iloc[i]['User_Percent']\n",
    "                                   )\n",
    "        folium.CircleMarker(location = [lat, long], radius=radius, popup= popup_text, fill =True).add_to(marker_cluster)\n",
    "#show the map\n",
    "world_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def entity_recognition (sentence):\n",
    "#     miscellaneous = []\n",
    "#     person = []\n",
    "#     organisation = []\n",
    "#     location = []\n",
    "#     for nlp_model in nlp_models:\n",
    "#         results =  nlp_model['model'].predict(sentence=sentence)\n",
    "#         for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "#             if tag != 'U-LOC':\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 # print([word])#(f\"{word}\")\n",
    "#                 location.append(word)\n",
    "#         # print()\n",
    "#         return location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def entity_recognition_per (sentence):\n",
    "#     miscellaneous = []\n",
    "#     person = []\n",
    "#     organisation = []\n",
    "#     location = []\n",
    "#     for nlp_model in nlp_models:\n",
    "#         results =  nlp_model['model'].predict(sentence=sentence)\n",
    "#         for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "#             if tag != 'U-ORG':\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 # print([word])#(f\"{word}\")\n",
    "#                 organisation.append(word)\n",
    "#         # print()\n",
    "#         return organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> Stashed changes
   "id": "e16439ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = '''Ben van Beurden, who took over in 2014, would leave Shell in the middle of the most severe energy crisis of his tenure. his departure would end a near-40-year career at the oil and gas giant in England and Ghana.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d81b898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Shell']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_recognition_per(sentences)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 174,
=======
=======
>>>>>>> Stashed changes
   "execution_count": null,
   "id": "3a984516",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[[\"text\",\"No.tokens\",\"summary\"]]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": 176,
=======
=======
>>>>>>> Stashed changes
   "execution_count": null,
   "id": "3a984516",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>No.tokens</th>\n",
       "      <th>summary</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shell’s long-serving chief executive, Ben van ...</td>\n",
       "      <td>698</td>\n",
       "      <td>van Beurden, who took over in 2014, would leav...</td>\n",
       "      <td>Shell declined to comment on Van Beurden’s pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A South African court has upheld a ban imposed...</td>\n",
       "      <td>395</td>\n",
       "      <td>the 2014 decision granting the right for the \"...</td>\n",
       "      <td>Shell did not say if it would appeal against t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gas shortages across Europe are likely to last...</td>\n",
       "      <td>1022</td>\n",
       "      <td>cuts to the supply of Russian gas since the in...</td>\n",
       "      <td>Shell made record profits of nearly £10bn betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell has agreed to pay half a million pounds ...</td>\n",
       "      <td>680</td>\n",
       "      <td>energy giant's consumer arm, shell energy reta...</td>\n",
       "      <td>The contributions Shell has made to the redres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The chair of the Church of England Pensions Bo...</td>\n",
       "      <td>1405</td>\n",
       "      <td>the church of england has rejected pressure to...</td>\n",
       "      <td>short-term expansion plans amount to about 4bn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  No.tokens  \\\n",
       "0  Shell’s long-serving chief executive, Ben van ...        698   \n",
       "1  A South African court has upheld a ban imposed...        395   \n",
       "2  Gas shortages across Europe are likely to last...       1022   \n",
       "3  Shell has agreed to pay half a million pounds ...        680   \n",
       "4  The chair of the Church of England Pensions Bo...       1405   \n",
       "\n",
       "                                             summary  \\\n",
       "0  van Beurden, who took over in 2014, would leav...   \n",
       "1  the 2014 decision granting the right for the \"...   \n",
       "2  cuts to the supply of Russian gas since the in...   \n",
       "3  energy giant's consumer arm, shell energy reta...   \n",
       "4  the church of england has rejected pressure to...   \n",
       "\n",
       "                                             answers  \n",
       "0  Shell declined to comment on Van Beurden’s pen...  \n",
       "1  Shell did not say if it would appeal against t...  \n",
       "2  Shell made record profits of nearly £10bn betw...  \n",
       "3  The contributions Shell has made to the redres...  \n",
       "4  short-term expansion plans amount to about 4bn...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"answers\"] = qestions(train,column= \"text\", question = \"Is Shell involved?\")\n",
    "train"
   ]
<<<<<<< Updated upstream
=======
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"test.csv\")"
   ]
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fb92d5742c001c91c37d9cc578d20237819f1079598661672d9831a3f737940"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
