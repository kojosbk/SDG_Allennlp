{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acf76510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from allennlp.predictors import Predictor\n",
    "from allennlp_models.pretrained import load_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb8d0f",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d6e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_models = [\n",
    "    { 'name' : 'ner-model',\n",
    "      'url': 'C:/Users/Silas_Dell/Downloads/Compressed/ner-elmo.2021-02-12.tar.gz'\n",
    "    },\n",
    "    # { 'name' : 'ner-elmo',\n",
    "    #   'url' : 'https://storage.googleapis.com/allennlp-public-models/ner-elmo.2021-02-12.tar.gz',\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9766901d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Loading model : ner-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\SILAS_~1\\AppData\\Local\\Temp\\tmp4_ckktct\\config.json as plain json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'ner-model' in 33,724.5 milli seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## load models\n",
    "print (\"Loading models...\")\n",
    "for nlp_model in nlp_models:\n",
    "    print (\"Loading model :\", nlp_model['name'])\n",
    "    t1 = time.perf_counter()\n",
    "    nlp_model['model'] = Predictor.from_path(nlp_model['url'])\n",
    "    t2 = time.perf_counter()\n",
    "    print (\"Loaded model '{}' in {:,.1f} milli seconds\".format (nlp_model['name'], (t2-t1)*1e3))\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "943b396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_recognition (sentence):\n",
    "    miscellaneous = []\n",
    "    person = []\n",
    "    organisation = []\n",
    "    location = []\n",
    "    for nlp_model in nlp_models:\n",
    "        results =  nlp_model['model'].predict(sentence=sentence)\n",
    "        for word, tag in zip(results[\"words\"], results[\"tags\"]):\n",
    "            if tag == 'U-LOC':\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"{word}\\t{tag}\")\n",
    "        print()\n",
    "        #return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e16439ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = '''Ben van Beurden, who took over in 2014, would leave Shell in the middle of the most severe energy crisis of his tenure. his departure would end a near-40-year career at the oil and gas giant in England and Ghana.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d81b898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ben\tB-PER\n",
      "van\tI-PER\n",
      "Beurden\tL-PER\n",
      ",\tO\n",
      "who\tO\n",
      "took\tO\n",
      "over\tO\n",
      "in\tO\n",
      "2014\tO\n",
      ",\tO\n",
      "would\tO\n",
      "leave\tO\n",
      "Shell\tU-ORG\n",
      "in\tO\n",
      "the\tO\n",
      "middle\tO\n",
      "of\tO\n",
      "the\tO\n",
      "most\tO\n",
      "severe\tO\n",
      "energy\tO\n",
      "crisis\tO\n",
      "of\tO\n",
      "his\tO\n",
      "tenure\tO\n",
      ".\tO\n",
      "his\tO\n",
      "departure\tO\n",
      "would\tO\n",
      "end\tO\n",
      "a\tO\n",
      "near-40\tO\n",
      "-\tO\n",
      "year\tO\n",
      "career\tO\n",
      "at\tO\n",
      "the\tO\n",
      "oil\tO\n",
      "and\tO\n",
      "gas\tO\n",
      "giant\tO\n",
      "in\tO\n",
      "and\tO\n",
      ".\tO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entity_recognition(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a984516",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(train[\"text\"])):\n",
    "    result.append(predictor.predict(passage=train[column][i], question=question)[\"best_span_str\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d3e26",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b57f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_csv('guardian_publications.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7931c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(df):\n",
    "    for name, values in sentences.text.iteritems():\n",
    "        x = name,values\n",
    "        sentence = str(x)\n",
    "        entity_recognition(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entities(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "811e911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London\n",
      "Europe\n",
      "Netherlands\n",
      "London\n",
      "UK\n",
      "Russia\n",
      "Ukraine\n",
      "Norway\n",
      "Makhanda\n",
      "Transkei\n",
      "Algoa\n",
      "Europe\n",
      "Ukraine\n",
      "Norway\n",
      "Europe\n",
      "Russia\n",
      "Ukraine\n",
      "Britain\n",
      "Russia\n",
      "Slovenia\n",
      "Belgium\n",
      "Norway\n",
      "Europe\n",
      "Russia\n",
      "Europe\n",
      "Europe\n",
      "Russia\n",
      "Germany\n",
      "Germany\n",
      "Britain\n",
      "UK\n",
      "Canada\n",
      "Britain\n",
      "Southwark\n",
      "Ascot\n",
      "Barisal\n",
      "Bangladesh\n",
      "Bangladesh\n",
      "Paris\n",
      "UK\n",
      "Russia\n",
      "Ukraine\n",
      "US\n",
      "UK\n",
      "US\n",
      "US\n",
      "US\n",
      "Texas\n",
      "Irving\n",
      "Texas\n",
      "Russia\n",
      "Ukraine\n",
      "Russia\n",
      "US\n",
      "Guyana\n",
      "US\n",
      "Britain\n",
      "Russia\n",
      "Ukraine\n",
      "UK\n",
      "UK\n",
      "UK\n",
      "US\n",
      "UK\n",
      "Europe\n",
      "Ukraine\n",
      "Russia\n",
      "Europe\n",
      "UK\n",
      "UK\n",
      "US\n",
      "US\n",
      "US\n",
      "US\n",
      "US\n",
      "Korea\n",
      "US\n",
      "Russia\n",
      "Ukraine\n",
      "UK\n",
      "UK\n",
      "Russia\n",
      "Russia\n",
      "Kremlin\n",
      "Ukraine\n",
      "Russia\n",
      "Spain\n",
      "Beirut\n",
      "Beirut\n",
      "Netherlands\n",
      "London\n",
      "Europe\n",
      "London\n",
      "Europe\n",
      "Netherlands\n",
      "London\n",
      "UK\n",
      "Russia\n",
      "Ukraine\n",
      "Norway\n",
      "Makhanda\n",
      "Transkei\n",
      "Algoa\n",
      "Europe\n",
      "Ukraine\n",
      "Norway\n",
      "Europe\n",
      "Russia\n",
      "Ukraine\n",
      "Britain\n",
      "Russia\n",
      "Slovenia\n",
      "Belgium\n",
      "Norway\n",
      "Europe\n",
      "Russia\n",
      "Europe\n",
      "Europe\n",
      "Russia\n",
      "Germany\n",
      "Germany\n",
      "Britain\n",
      "UK\n",
      "Canada\n",
      "Britain\n",
      "Southwark\n",
      "Ascot\n",
      "Barisal\n",
      "Bangladesh\n",
      "Bangladesh\n",
      "Paris\n",
      "UK\n",
      "Russia\n",
      "Ukraine\n",
      "US\n",
      "UK\n",
      "US\n",
      "US\n",
      "US\n",
      "Texas\n",
      "Irving\n",
      "Texas\n",
      "Russia\n",
      "Ukraine\n",
      "Russia\n",
      "US\n",
      "Guyana\n",
      "US\n",
      "Britain\n",
      "US\n",
      "Russia\n",
      "Ukraine\n",
      "UK\n",
      "UK\n",
      "UK\n",
      "US\n",
      "UK\n",
      "Europe\n",
      "Ukraine\n",
      "Russia\n",
      "Europe\n",
      "UK\n",
      "UK\n",
      "US\n",
      "US\n",
      "US\n",
      "US\n",
      "US\n",
      "Korea\n",
      "US\n",
      "Russia\n",
      "Ukraine\n",
      "UK\n",
      "UK\n",
      "Russia\n",
      "Russia\n",
      "Kremlin\n",
      "Ukraine\n",
      "Russia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=sentences[\"text\"].head(1).apply(get_entities)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a2e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "320c1f05b41b6296d6cdeadbc8f37198b22e160db062b16d8b8cc9d95c25d782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
