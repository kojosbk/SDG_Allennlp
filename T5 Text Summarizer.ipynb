{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "robust-session",
   "metadata": {},
   "source": [
    "# T5 Text Summarizer\n",
    "\n",
    "This Jupyter Notebook demonstrates how Google's T5 pre-train model is used to generate summary.\n",
    "\n",
    "Please ensure both Python packages below have been 'pip' installed.\n",
    "\n",
    "```pip install torch```\n",
    "\n",
    "```pip install transformers```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-hours",
   "metadata": {},
   "source": [
    "## Import Libraries / Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "domestic-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-cargo",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decreased-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Silas_Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-context",
   "metadata": {},
   "source": [
    "## Input Text\n",
    "\n",
    "Load CNN [news](https://edition.cnn.com/2021/04/21/media/netflix-earnings-analysis/index.html) in text form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coated-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "One challenge that Kingdom preachers face is opposition. Apostates, religious leaders, and politicians have given many the wrong impression about our work. If our relatives, acquaintances, and workmates are misled by this propaganda, they may pressure us to stop serving Jehovah and to stop preaching. In some countries, the opposition takes the form of intimidation, threats, arrests, and even imprisonment. We are not surprised at this reaction. Jesus foretold: “You will be hated by all the nations on account of my name.” (Matt. 24:9) The very fact that we are experiencing such hatred is proof that we have Jehovah’s approval. (Matt. 5:11, 12) The Devil is behind this opposition. But he is no match for Jesus! With Jesus’ support, the good news is reaching people of all nations. Consider the evidence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-contact",
   "metadata": {},
   "source": [
    "## Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entitled-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input = tokenizer.encode(\"summarize: \"+text, return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-entity",
   "metadata": {},
   "source": [
    "## Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "resident-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(tokens_input, min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2)\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "comic-tribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apostates, religious leaders, and politicians have given many the wrong impression about our work. if relatives, acquaintances, and workmates are misled by this propaganda, they may pressure us to stop preaching. with Jesus’ support, the good news is reaching people of all nations. consider the evidence. apostasy, christianity, and apostasy are just a few of the challenges that kingdom preachers face - apostasy, christi\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lasting-microphone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tokens generated from the text using T5 Tokenizer\n",
    "len(tokenizer(text)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "soviet-theta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model maximum acceptable token inputs length\n",
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-mercury",
   "metadata": {},
   "source": [
    "# BERT Extractive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-stage",
   "metadata": {},
   "source": [
    "Number of tokenized text exceeds (>) maximum acceptable token inputs length, this means that the latter text will be truncated and won't be fed into the T5 summarizer model.\n",
    "\n",
    "To solve the risk of missing out important details in the latter text, let's perform extractive summarization followed by abstractive summarization.\n",
    "\n",
    "Before we proceed, make sure we have pip installed BERT extractive summarizer.\n",
    "\n",
    "```pip install bert-extractive-summarizer```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chinese-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT summarizer module\n",
    "from summarizer import Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-amount",
   "metadata": {},
   "source": [
    "Use BERT summarizer to extract only top 50% of sentences that are considered important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hollow-optimization",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = Summarizer()\n",
    "ext_summary = bert_model(text, ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rational-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One challenge that Kingdom preachers face is opposition. Apostates, religious leaders, and politicians have given many the wrong impression about our work. 24:9) The very fact that we are experiencing such hatred is proof that we have Jehovah’s approval. ( 5:11, 12) The Devil is behind this opposition.\n"
     ]
    }
   ],
   "source": [
    "print(ext_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-mitchell",
   "metadata": {},
   "source": [
    "## Tokenize BERT Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "modular-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_2 = tokenizer.encode(\"summarize: \"+ext_summary, return_tensors='pt', \n",
    "                                max_length=tokenizer.model_max_length, \n",
    "                                truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "latter-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(ext_summary)['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-equation",
   "metadata": {},
   "source": [
    "The number of tokenized text is just slightly exceeded the maximum acceptable token inputs length (521 > 512), this is okay because this won't make much different to the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-webmaster",
   "metadata": {},
   "source": [
    "## Extractive-Abstractive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ranking-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids_2 = model.generate(tokens_input_2, min_length=80,\n",
    "                             max_length=150,\n",
    "                             length_penalty=20, \n",
    "                             num_beams=2)\n",
    "\n",
    "summary_2 = tokenizer.decode(summary_ids_2[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "monetary-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apostates, religious leaders, and politicians have given many the wrong impression about our work. the very fact that we are experiencing such hatred is proof that we have Jehovah’s approval. the very fact that we are experiencing such hatred is proof that we have Jehovah’s approval. apostates, religious leaders, and politicians have given many the wrong impression about our work.\n"
     ]
    }
   ],
   "source": [
    "print(summary_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-pressure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "320c1f05b41b6296d6cdeadbc8f37198b22e160db062b16d8b8cc9d95c25d782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
